{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iiOZAYaOjsIB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import datasets, layers, models, optimizers, regularizers, callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KzfGgXfPjsIP"
   },
   "outputs": [],
   "source": [
    "# Here we create a dict which consists label for each image path and its particular data.\n",
    "def load_file(file_path, label):\n",
    "\n",
    "    # declare the folder name\n",
    "    folder_name = file_path.split(\"/\")[-1]\n",
    "    # declare output list\n",
    "    out_list = []\n",
    "    # load every file that .png format\n",
    "    for image_path in glob.glob(file_path + \"/*.*\"):\n",
    "        # read image file\n",
    "        # image = imageio.imread(image_path)\n",
    "        image = imageio.v2.imread(image_path)   \n",
    "        # print(image_path)\n",
    "        # declare temporary dict dtype\n",
    "        temp = {}\n",
    "        # set the file name\n",
    "        temp[\"name\"] = image_path.split(\"/\")[-1]\n",
    "        # set the file label, 0 for non defect. 1 for defect\n",
    "        temp[\"label\"] = label\n",
    "\n",
    "        # There are somes images are tensor dtype\n",
    "        # Thus I fix by selecting only a tensor index zero\n",
    "        try:   \n",
    "            temp[\"data\"] = image[:,:,0].astype(\"int\") \n",
    "        except:\n",
    "            # normal case\n",
    "            temp[\"data\"] = image.astype(\"int\")\n",
    "        # append temp into output list\n",
    "        out_list.append(temp)\n",
    "    # print process status by checking size of output list\n",
    "    if len(out_list) == 0:\n",
    "        print(\"loading files from folder: {} is failed\".format(folder_name))\n",
    "    else:\n",
    "        print(\"loading file from folder: {} is successful\".format(folder_name))\n",
    "    # convert list into numpy array dtype\n",
    "    return np.array(out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VBe3NgxyjsIS"
   },
   "outputs": [],
   "source": [
    "acnitic_images_path      =  r\"C:\\Users\\lenovo\\Downloads\\skin canser\\augmented_new_data\\A\"\n",
    "derma_images_path =  r\"C:\\Users\\lenovo\\Downloads\\skin canser\\augmented_new_data\\D\"\n",
    "vascular_images_path =  r\"C:\\Users\\lenovo\\Downloads\\skin canser\\augmented_new_data\\V\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1674224644830,
     "user": {
      "displayName": "Sanjay M",
      "userId": "09124300212410739662"
     },
     "user_tz": -330
    },
    "id": "2YYplWjOjsIU",
    "outputId": "044209e8-996f-49a0-8a9f-d4e480cd1f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file from folder: C:\\Users\\lenovo\\Downloads\\skin canser\\augmented_new_data\\A is successful\n",
      "loading file from folder: C:\\Users\\lenovo\\Downloads\\skin canser\\augmented_new_data\\D is successful\n",
      "loading file from folder: C:\\Users\\lenovo\\Downloads\\skin canser\\augmented_new_data\\V is successful\n"
     ]
    }
   ],
   "source": [
    "acnitic_images_path = load_file(file_path=acnitic_images_path, label=0)\n",
    "derma_images_path = load_file(file_path=derma_images_path, label=1)\n",
    "vascular_images_path = load_file(file_path=vascular_images_path, label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1674224647700,
     "user": {
      "displayName": "Sanjay M",
      "userId": "09124300212410739662"
     },
     "user_tz": -330
    },
    "id": "cALktAzEjsIa",
    "outputId": "39440633-a1de-4381-c949-618e650b6d70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1186,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acnitic_images_path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4C8wfGR7jsIc",
    "outputId": "b3c20673-67d9-4f3c-ec8d-348c579bb6f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1171,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derma_images_path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7jVuO-WYjsIe",
    "outputId": "8f8a37a2-ad03-4fa7-b57e-f83e3f335855"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1307,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vascular_images_path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7fB9iQpjsIg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-K8I31zjsIh"
   },
   "source": [
    "## **Prepare and clean the data to avoid error during model fitting.**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Yq2hpF-GjsIl",
    "outputId": "f8de13db-8e20-40c1-c60d-016545e6b146"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Size: 1171\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(acnitic_images_path)\n",
    "np.random.shuffle(derma_images_path)\n",
    "np.random.shuffle(vascular_images_path)\n",
    "\n",
    "# the class size is the min length compared with defect-free and defect images, we do this in orde to balance the dataset.\n",
    "if (acnitic_images_path.shape[0] <= derma_images_path.shape[0]) and (acnitic_images_path.shape[0] <= vascular_images_path.shape[0]):\n",
    "  class_size = acnitic_images_path.shape[0]\n",
    "elif (derma_images_path.shape[0] <= vascular_images_path.shape[0]) and (derma_images_path.shape[0] <= acnitic_images_path.shape[0]):\n",
    "  class_size = derma_images_path.shape[0]\n",
    "else:\n",
    "  class_size = vascular_images_path.shape[0]\n",
    "print(\"Class Size:\", class_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FrHFHdY9jsIo",
    "outputId": "1f8b0a26-7187-4092-ee3d-ed51db693d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3513, 180, 180, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([1171, 1171, 1171], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we shuffle the order of defect-free and defect images\n",
    "np.random.shuffle(acnitic_images_path)\n",
    "np.random.shuffle(derma_images_path)\n",
    "np.random.shuffle(vascular_images_path)\n",
    "\n",
    "# Concatenate both the datasets with size as class_size.\n",
    "dataset = np.concatenate((acnitic_images_path[:class_size], derma_images_path[:class_size], vascular_images_path[:class_size]))\n",
    "\n",
    "# create an empty matrix X of 256x4096 and has dataset length row, which holds all the data i.e images from dataset.\n",
    "# Independent Features -> X\n",
    "X = np.empty([dataset.shape[0], 180, 180]).astype(int)\n",
    "\n",
    "# create vector y which has dataset length, which holds all the labels for our data, this is jsut similar to partitioning the data before splitting, \n",
    "# Target_variable -> y\n",
    "y = np.empty(dataset.shape[0]).astype(int)\n",
    "\n",
    "# assign the X,y one-by-one\n",
    "for i in range(dataset.shape[0]):\n",
    "    X[i] = dataset[i][\"data\"]\n",
    "    y[i] = dataset[i][\"label\"]\n",
    "\n",
    "# since Keras acquire the Image input in a tensor type -> we reshape X\n",
    "X = X.reshape(X.shape[0], 180, 180, 1)\n",
    "print(X.shape)\n",
    "\n",
    "# display size of the label 0 and label 1 \n",
    "np.unique(y, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "unf1R77ujsIr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFpJvEX2jsIs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOdtRNhVjsIt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2P69nl1jsIu"
   },
   "source": [
    "## **Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "K2XRq3tWjsIv",
    "outputId": "78332ea1-cefb-4f0e-96fa-7bdd4c48e75e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 180, 180, 1)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 180, 180, 16)      160       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 180, 180, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 90, 90, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 90, 90, 32)        4640      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 90, 90, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 45, 45, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 45, 45, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 22, 22, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3965056   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,988,739\n",
      "Trainable params: 3,988,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x230a2be3d90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_model(image_shape = (180, 180, 1), print_summary = True):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(180, 180, 1)))\n",
    "    model.add(layers.Conv2D(16, 3, padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "\n",
    "    model.add(layers.Conv2D(32, 3, padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "\n",
    "    model.add(layers.Conv2D(64, 3, padding='same'))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Dropout(0.20))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128))\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.Dense(3, activation = 'sigmoid'))\n",
    "\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    \n",
    "    # show the CNN model detail\n",
    "    if print_summary:\n",
    "        model.summary()\n",
    "    return model\n",
    "\n",
    "def train_model(model, xtrain, ytrain, xval, yval, n_epoch, batch_size):\n",
    "    # train CNN model\n",
    "    # batch size to reduce memory usage\n",
    "    # set early stopping to avoid overfitting\n",
    "    \n",
    "    earlystopping = EarlyStopping(monitor='accuracy', patience=2)\n",
    "    filepath = \"C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy/weights-best-{epoch:02d}-{accuracy:.2f}-{val_accuracy:.2f}.hdf5\"\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint, earlystopping]\n",
    "\n",
    "    history = model.fit(xtrain, ytrain, epochs=n_epoch, batch_size=batch_size, validation_data=(xval, yval), callbacks=[callbacks_list])\n",
    "    return history\n",
    "\n",
    "\n",
    "create_model(image_shape=(180, 180, 1), print_summary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZqUQ-wqjsIw"
   },
   "source": [
    "## Train and Export CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Ru7JcKbijsIx",
    "outputId": "18f95479-9e71-4af8-a7b4-c02ab997bd4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: number of samples each class: (array([0, 1, 2]), array([1054, 1050, 1057], dtype=int64))\n",
      "y_test: number of samples each class: (array([0, 1, 2]), array([117, 121, 114], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=23)\n",
    "print(\"y_train: number of samples each class: {}\".format(np.unique(y_train, return_counts=True)))\n",
    "print(\"y_test: number of samples each class: {}\".format(np.unique(y_test, return_counts=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3uR5WnsbjsIy",
    "outputId": "5fbc05f5-90bd-4286-8a7d-f6b9218aaaa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 180, 180, 1)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 180, 180, 16)      160       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 180, 180, 16)      0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 90, 90, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 90, 90, 32)        4640      \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 90, 90, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 45, 45, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 45, 45, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 22, 22, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 30976)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               3965056   \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,988,739\n",
      "Trainable params: 3,988,739\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model = None\n",
    "cnn_model = create_model(image_shape=(180, 180, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrKkpdlRjsIz"
   },
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor='accuracy', patience=5)\n",
    "filepath = \"C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy/weights-best-{epoch:02d}-{accuracy:.2f}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint, earlystopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FkdfgbNDjsI0",
    "outputId": "5d75a0a0-3d1a-4b32-adc6-48c9af10ea61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heman\\anaconda3\\lib\\site-packages\\keras\\backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - ETA: 0s - loss: 1.0788 - accuracy: 0.3674\n",
      "Epoch 1: accuracy improved from -inf to 0.36738, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-01-0.37-0.38.hdf5\n",
      "282/282 [==============================] - 70s 236ms/step - loss: 1.0788 - accuracy: 0.3674 - val_loss: 1.0631 - val_accuracy: 0.3790\n",
      "Epoch 2/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 1.0267 - accuracy: 0.4135\n",
      "Epoch 2: accuracy improved from 0.36738 to 0.41348, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-02-0.41-0.41.hdf5\n",
      "282/282 [==============================] - 66s 235ms/step - loss: 1.0267 - accuracy: 0.4135 - val_loss: 1.0369 - val_accuracy: 0.4076\n",
      "Epoch 3/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.9963 - accuracy: 0.4401\n",
      "Epoch 3: accuracy improved from 0.41348 to 0.44007, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-03-0.44-0.43.hdf5\n",
      "282/282 [==============================] - 66s 234ms/step - loss: 0.9963 - accuracy: 0.4401 - val_loss: 1.0072 - val_accuracy: 0.4299\n",
      "Epoch 4/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.9770 - accuracy: 0.4582\n",
      "Epoch 4: accuracy improved from 0.44007 to 0.45816, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-04-0.46-0.42.hdf5\n",
      "282/282 [==============================] - 67s 237ms/step - loss: 0.9770 - accuracy: 0.4582 - val_loss: 1.0219 - val_accuracy: 0.4236\n",
      "Epoch 5/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.9647 - accuracy: 0.4713\n",
      "Epoch 5: accuracy improved from 0.45816 to 0.47128, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-05-0.47-0.47.hdf5\n",
      "282/282 [==============================] - 67s 237ms/step - loss: 0.9647 - accuracy: 0.4713 - val_loss: 1.0840 - val_accuracy: 0.4713\n",
      "Epoch 6/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.9297 - accuracy: 0.5181\n",
      "Epoch 6: accuracy improved from 0.47128 to 0.51809, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-06-0.52-0.47.hdf5\n",
      "282/282 [==============================] - 67s 236ms/step - loss: 0.9297 - accuracy: 0.5181 - val_loss: 1.0127 - val_accuracy: 0.4682\n",
      "Epoch 7/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.8866 - accuracy: 0.5592\n",
      "Epoch 7: accuracy improved from 0.51809 to 0.55922, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-07-0.56-0.54.hdf5\n",
      "282/282 [==============================] - 66s 235ms/step - loss: 0.8866 - accuracy: 0.5592 - val_loss: 0.9408 - val_accuracy: 0.5382\n",
      "Epoch 8/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.8765 - accuracy: 0.5564\n",
      "Epoch 8: accuracy did not improve from 0.55922\n",
      "282/282 [==============================] - 68s 243ms/step - loss: 0.8765 - accuracy: 0.5564 - val_loss: 1.0449 - val_accuracy: 0.5414\n",
      "Epoch 9/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.8170 - accuracy: 0.6046\n",
      "Epoch 9: accuracy improved from 0.55922 to 0.60461, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-09-0.60-0.51.hdf5\n",
      "282/282 [==============================] - 67s 238ms/step - loss: 0.8170 - accuracy: 0.6046 - val_loss: 0.9905 - val_accuracy: 0.5127\n",
      "Epoch 10/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.7815 - accuracy: 0.6128\n",
      "Epoch 10: accuracy improved from 0.60461 to 0.61277, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-10-0.61-0.54.hdf5\n",
      "282/282 [==============================] - 75s 266ms/step - loss: 0.7815 - accuracy: 0.6128 - val_loss: 1.0543 - val_accuracy: 0.5446\n",
      "Epoch 11/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.7498 - accuracy: 0.6454\n",
      "Epoch 11: accuracy improved from 0.61277 to 0.64539, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-11-0.65-0.55.hdf5\n",
      "282/282 [==============================] - 65s 229ms/step - loss: 0.7498 - accuracy: 0.6454 - val_loss: 1.0832 - val_accuracy: 0.5478\n",
      "Epoch 12/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.7008 - accuracy: 0.6798\n",
      "Epoch 12: accuracy improved from 0.64539 to 0.67979, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-12-0.68-0.58.hdf5\n",
      "282/282 [==============================] - 65s 230ms/step - loss: 0.7008 - accuracy: 0.6798 - val_loss: 1.0594 - val_accuracy: 0.5828\n",
      "Epoch 13/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.6205 - accuracy: 0.7113\n",
      "Epoch 13: accuracy improved from 0.67979 to 0.71135, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-13-0.71-0.60.hdf5\n",
      "282/282 [==============================] - 66s 233ms/step - loss: 0.6205 - accuracy: 0.7113 - val_loss: 1.1885 - val_accuracy: 0.6019\n",
      "Epoch 14/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.5362 - accuracy: 0.7589\n",
      "Epoch 14: accuracy improved from 0.71135 to 0.75887, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-14-0.76-0.64.hdf5\n",
      "282/282 [==============================] - 66s 234ms/step - loss: 0.5362 - accuracy: 0.7589 - val_loss: 1.1270 - val_accuracy: 0.6369\n",
      "Epoch 15/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4648 - accuracy: 0.7897\n",
      "Epoch 15: accuracy improved from 0.75887 to 0.78972, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-15-0.79-0.66.hdf5\n",
      "282/282 [==============================] - 66s 235ms/step - loss: 0.4648 - accuracy: 0.7897 - val_loss: 1.3943 - val_accuracy: 0.6561\n",
      "Epoch 16/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4138 - accuracy: 0.8270\n",
      "Epoch 16: accuracy improved from 0.78972 to 0.82695, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-16-0.83-0.63.hdf5\n",
      "282/282 [==============================] - 66s 233ms/step - loss: 0.4138 - accuracy: 0.8270 - val_loss: 1.3945 - val_accuracy: 0.6274\n",
      "Epoch 17/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3427 - accuracy: 0.8660\n",
      "Epoch 17: accuracy improved from 0.82695 to 0.86596, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-17-0.87-0.67.hdf5\n",
      "282/282 [==============================] - 67s 236ms/step - loss: 0.3427 - accuracy: 0.8660 - val_loss: 1.3055 - val_accuracy: 0.6656\n",
      "Epoch 18/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.3265 - accuracy: 0.8812\n",
      "Epoch 18: accuracy improved from 0.86596 to 0.88121, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-18-0.88-0.61.hdf5\n",
      "282/282 [==============================] - 66s 232ms/step - loss: 0.3265 - accuracy: 0.8812 - val_loss: 1.4292 - val_accuracy: 0.6146\n",
      "Epoch 19/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.9184\n",
      "Epoch 19: accuracy improved from 0.88121 to 0.91844, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-19-0.92-0.66.hdf5\n",
      "282/282 [==============================] - 67s 237ms/step - loss: 0.2366 - accuracy: 0.9184 - val_loss: 1.4243 - val_accuracy: 0.6592\n",
      "Epoch 20/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1811 - accuracy: 0.9397\n",
      "Epoch 20: accuracy improved from 0.91844 to 0.93972, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-20-0.94-0.67.hdf5\n",
      "282/282 [==============================] - 66s 234ms/step - loss: 0.1811 - accuracy: 0.9397 - val_loss: 1.8627 - val_accuracy: 0.6656\n",
      "Epoch 21/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9514\n",
      "Epoch 21: accuracy improved from 0.93972 to 0.95142, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-21-0.95-0.71.hdf5\n",
      "282/282 [==============================] - 64s 228ms/step - loss: 0.1396 - accuracy: 0.9514 - val_loss: 1.8977 - val_accuracy: 0.7070\n",
      "Epoch 22/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1135 - accuracy: 0.9617\n",
      "Epoch 22: accuracy improved from 0.95142 to 0.96170, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-22-0.96-0.69.hdf5\n",
      "282/282 [==============================] - 67s 236ms/step - loss: 0.1135 - accuracy: 0.9617 - val_loss: 2.2303 - val_accuracy: 0.6943\n",
      "Epoch 23/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9585\n",
      "Epoch 23: accuracy did not improve from 0.96170\n",
      "282/282 [==============================] - 65s 231ms/step - loss: 0.1399 - accuracy: 0.9585 - val_loss: 1.8042 - val_accuracy: 0.7006\n",
      "Epoch 24/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.9628\n",
      "Epoch 24: accuracy improved from 0.96170 to 0.96277, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-24-0.96-0.67.hdf5\n",
      "282/282 [==============================] - 64s 228ms/step - loss: 0.1116 - accuracy: 0.9628 - val_loss: 2.5827 - val_accuracy: 0.6688\n",
      "Epoch 25/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9837\n",
      "Epoch 25: accuracy improved from 0.96277 to 0.98369, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-25-0.98-0.68.hdf5\n",
      "282/282 [==============================] - 65s 230ms/step - loss: 0.0568 - accuracy: 0.9837 - val_loss: 2.6601 - val_accuracy: 0.6752\n",
      "Epoch 26/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 0.9894\n",
      "Epoch 26: accuracy improved from 0.98369 to 0.98936, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-26-0.99-0.69.hdf5\n",
      "282/282 [==============================] - 65s 229ms/step - loss: 0.0441 - accuracy: 0.9894 - val_loss: 2.6806 - val_accuracy: 0.6943\n",
      "Epoch 27/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9933\n",
      "Epoch 27: accuracy improved from 0.98936 to 0.99326, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-27-0.99-0.70.hdf5\n",
      "282/282 [==============================] - 65s 230ms/step - loss: 0.0302 - accuracy: 0.9933 - val_loss: 2.6203 - val_accuracy: 0.7006\n",
      "Epoch 28/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9901\n",
      "Epoch 28: accuracy did not improve from 0.99326\n",
      "282/282 [==============================] - 65s 229ms/step - loss: 0.0308 - accuracy: 0.9901 - val_loss: 2.8927 - val_accuracy: 0.6879\n",
      "Epoch 29/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9663\n",
      "Epoch 29: accuracy did not improve from 0.99326\n",
      "282/282 [==============================] - 65s 230ms/step - loss: 0.1214 - accuracy: 0.9663 - val_loss: 2.5272 - val_accuracy: 0.6783\n",
      "Epoch 30/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9904\n",
      "Epoch 30: accuracy did not improve from 0.99326\n",
      "282/282 [==============================] - 63s 224ms/step - loss: 0.0414 - accuracy: 0.9904 - val_loss: 2.1491 - val_accuracy: 0.6943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e04a518e80>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No need to run this, if you are loading the model, if not you cna run this to train your model again and save another weights file.\n",
    "cnn_model.fit(X_train, y_train, batch_size=10, epochs=20, validation_split=0.1, callbacks=callbacks_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pA5Smj0EjsI2",
    "outputId": "79adfee6-c4fb-4dc8-e7f9-647deea2aaca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.25661563873291, 0.6590257883071899)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, acc = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "score, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7czEAeZjsI3"
   },
   "outputs": [],
   "source": [
    "# Starting the training where we have stopped.\n",
    "# cnn_model.fit(X_train, y_train, batch_size=10, initial_epochs=10, validation_split=0.1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WSjO5N6jsI4"
   },
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model('C:/Users/heman/Downloads/Capstone_Project/SKIN/models/weights-best-04-0.91-0.73.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ekmaXwKjsI4",
    "outputId": "1c532587-0b7d-4c80-b291-217e53722da8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4080801010131836, 0.8767908215522766)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, acc = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "score, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaoGWKjojsI5",
    "outputId": "52deb47d-9f37-4220-8d1d-1305d3a37259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.8433\n",
      "Epoch 1: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 64s 224ms/step - loss: 0.4727 - accuracy: 0.8433 - val_loss: 0.5704 - val_accuracy: 0.7771\n",
      "Epoch 2/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2866 - accuracy: 0.9004\n",
      "Epoch 2: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 62s 221ms/step - loss: 0.2866 - accuracy: 0.9004 - val_loss: 0.3835 - val_accuracy: 0.8758\n",
      "Epoch 3/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2075 - accuracy: 0.9245\n",
      "Epoch 3: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 62s 221ms/step - loss: 0.2075 - accuracy: 0.9245 - val_loss: 0.4105 - val_accuracy: 0.8790\n",
      "Epoch 4/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9397\n",
      "Epoch 4: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 62s 221ms/step - loss: 0.1750 - accuracy: 0.9397 - val_loss: 0.5189 - val_accuracy: 0.7962\n",
      "Epoch 5/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1417 - accuracy: 0.9507\n",
      "Epoch 5: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 63s 222ms/step - loss: 0.1417 - accuracy: 0.9507 - val_loss: 0.4641 - val_accuracy: 0.8631\n",
      "Epoch 6/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.9656\n",
      "Epoch 6: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 64s 226ms/step - loss: 0.1044 - accuracy: 0.9656 - val_loss: 0.6297 - val_accuracy: 0.8662\n",
      "Epoch 7/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1110 - accuracy: 0.9663\n",
      "Epoch 7: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 63s 224ms/step - loss: 0.1110 - accuracy: 0.9663 - val_loss: 0.7220 - val_accuracy: 0.7930\n",
      "Epoch 8/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 67s 238ms/step - loss: 0.0751 - accuracy: 0.9787 - val_loss: 0.7399 - val_accuracy: 0.8025\n",
      "Epoch 9/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.9755\n",
      "Epoch 9: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 64s 226ms/step - loss: 0.0761 - accuracy: 0.9755 - val_loss: 0.8177 - val_accuracy: 0.8217\n",
      "Epoch 10/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9816\n",
      "Epoch 10: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 63s 224ms/step - loss: 0.0602 - accuracy: 0.9816 - val_loss: 0.7102 - val_accuracy: 0.8344\n",
      "Epoch 11/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9819\n",
      "Epoch 11: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 73s 258ms/step - loss: 0.0622 - accuracy: 0.9819 - val_loss: 0.7500 - val_accuracy: 0.8535\n",
      "Epoch 12/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9869\n",
      "Epoch 12: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 66s 236ms/step - loss: 0.0496 - accuracy: 0.9869 - val_loss: 0.7924 - val_accuracy: 0.8089\n",
      "Epoch 13/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9915\n",
      "Epoch 13: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 68s 242ms/step - loss: 0.0348 - accuracy: 0.9915 - val_loss: 0.7592 - val_accuracy: 0.8535\n",
      "Epoch 14/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.9723\n",
      "Epoch 14: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 69s 243ms/step - loss: 0.0826 - accuracy: 0.9723 - val_loss: 0.8445 - val_accuracy: 0.8057\n",
      "Epoch 15/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9894\n",
      "Epoch 15: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 68s 240ms/step - loss: 0.0388 - accuracy: 0.9894 - val_loss: 0.8029 - val_accuracy: 0.8312\n",
      "Epoch 16/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9940\n",
      "Epoch 16: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 68s 241ms/step - loss: 0.0199 - accuracy: 0.9940 - val_loss: 0.7680 - val_accuracy: 0.8503\n",
      "Epoch 17/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9950\n",
      "Epoch 17: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 68s 240ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.7459 - val_accuracy: 0.8376\n",
      "Epoch 18/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9943\n",
      "Epoch 18: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 68s 242ms/step - loss: 0.0234 - accuracy: 0.9943 - val_loss: 0.8337 - val_accuracy: 0.8185\n",
      "Epoch 19/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.9617\n",
      "Epoch 19: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 68s 241ms/step - loss: 0.1458 - accuracy: 0.9617 - val_loss: 0.7051 - val_accuracy: 0.8280\n",
      "Epoch 20/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9915\n",
      "Epoch 20: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 70s 249ms/step - loss: 0.0348 - accuracy: 0.9915 - val_loss: 1.0592 - val_accuracy: 0.7771\n",
      "Epoch 21/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9957\n",
      "Epoch 21: accuracy did not improve from 0.99787\n",
      "282/282 [==============================] - 69s 245ms/step - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.8245 - val_accuracy: 0.8057\n",
      "Epoch 22/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9993\n",
      "Epoch 22: accuracy improved from 0.99787 to 0.99929, saving model to C:/Users/heman/Downloads/Capstone_Project/SKIN/models/different_class_accuracy\\weights-best-22-1.00-0.82.hdf5\n",
      "282/282 [==============================] - 67s 236ms/step - loss: 0.0063 - accuracy: 0.9993 - val_loss: 0.8113 - val_accuracy: 0.8248\n",
      "Epoch 23/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9989\n",
      "Epoch 23: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 68s 241ms/step - loss: 0.0052 - accuracy: 0.9989 - val_loss: 0.9911 - val_accuracy: 0.8248\n",
      "Epoch 24/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9940\n",
      "Epoch 24: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 67s 236ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 1.1850 - val_accuracy: 0.7898\n",
      "Epoch 25/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9759\n",
      "Epoch 25: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 67s 236ms/step - loss: 0.0879 - accuracy: 0.9759 - val_loss: 0.9228 - val_accuracy: 0.8121\n",
      "Epoch 26/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9926\n",
      "Epoch 26: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 61s 215ms/step - loss: 0.0375 - accuracy: 0.9926 - val_loss: 1.3354 - val_accuracy: 0.7484\n",
      "Epoch 27/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9879\n",
      "Epoch 27: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 52s 185ms/step - loss: 0.0521 - accuracy: 0.9879 - val_loss: 0.8434 - val_accuracy: 0.8439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e0a9f97fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No need to run this, if you are loading the model, if not you cna run this to train your model again and save another weights file.\n",
    "loaded_model.fit(X_train, y_train, batch_size=10, epochs=30, validation_split=0.1, callbacks=callbacks_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJwMZAWQjsI7",
    "outputId": "eb11285b-7b3d-44c9-ad00-248b6566b19e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8856669664382935, 0.8051576018333435)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, acc = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "score, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zb5McGjqjsI8"
   },
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "loaded_model_2 = load_model('C:/Users/heman/Downloads/Capstone_Project/SKIN/models/weights-best-04-0.91-0.73.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OtlNTwhhjsI-",
    "outputId": "2a7af333-1849-438d-d9aa-f171a156d87d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4080801010131836, 0.8767908215522766)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, acc = loaded_model_2.evaluate(X_test, y_test, verbose=0)\n",
    "score, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sAq99-TjsI_",
    "outputId": "b6bf79a2-a08a-48c9-c890-9761aeea602e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.4491 - accuracy: 0.8489\n",
      "Epoch 1: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 53s 187ms/step - loss: 0.4491 - accuracy: 0.8489 - val_loss: 0.3927 - val_accuracy: 0.8599\n",
      "Epoch 2/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.9067\n",
      "Epoch 2: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 61s 216ms/step - loss: 0.2740 - accuracy: 0.9067 - val_loss: 0.3942 - val_accuracy: 0.8694\n",
      "Epoch 3/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.2025 - accuracy: 0.9298\n",
      "Epoch 3: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 51s 180ms/step - loss: 0.2025 - accuracy: 0.9298 - val_loss: 0.4342 - val_accuracy: 0.8662\n",
      "Epoch 4/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.9450\n",
      "Epoch 4: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 49s 172ms/step - loss: 0.1652 - accuracy: 0.9450 - val_loss: 0.4501 - val_accuracy: 0.8917\n",
      "Epoch 5/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9621\n",
      "Epoch 5: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 49s 174ms/step - loss: 0.1132 - accuracy: 0.9621 - val_loss: 0.5848 - val_accuracy: 0.8471\n",
      "Epoch 6/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9667\n",
      "Epoch 6: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 54s 191ms/step - loss: 0.1014 - accuracy: 0.9667 - val_loss: 0.5242 - val_accuracy: 0.8599\n",
      "Epoch 7/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 0.9652\n",
      "Epoch 7: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 54s 192ms/step - loss: 0.0972 - accuracy: 0.9652 - val_loss: 0.5971 - val_accuracy: 0.8503\n",
      "Epoch 8/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9787\n",
      "Epoch 8: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 52s 183ms/step - loss: 0.0733 - accuracy: 0.9787 - val_loss: 0.5938 - val_accuracy: 0.8567\n",
      "Epoch 9/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.9883\n",
      "Epoch 9: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 48s 170ms/step - loss: 0.0446 - accuracy: 0.9883 - val_loss: 0.8409 - val_accuracy: 0.8439\n",
      "Epoch 10/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 0.9748\n",
      "Epoch 10: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 47s 168ms/step - loss: 0.0780 - accuracy: 0.9748 - val_loss: 0.5616 - val_accuracy: 0.8503\n",
      "Epoch 11/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9837\n",
      "Epoch 11: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 56s 198ms/step - loss: 0.0583 - accuracy: 0.9837 - val_loss: 0.6772 - val_accuracy: 0.8535\n",
      "Epoch 12/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9883\n",
      "Epoch 12: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 68s 241ms/step - loss: 0.0421 - accuracy: 0.9883 - val_loss: 0.8913 - val_accuracy: 0.8185\n",
      "Epoch 13/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1183 - accuracy: 0.9670\n",
      "Epoch 13: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 70s 247ms/step - loss: 0.1183 - accuracy: 0.9670 - val_loss: 0.9546 - val_accuracy: 0.8121\n",
      "Epoch 14/30\n",
      "282/282 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.9716\n",
      "Epoch 14: accuracy did not improve from 0.99929\n",
      "282/282 [==============================] - 61s 216ms/step - loss: 0.1042 - accuracy: 0.9716 - val_loss: 0.7524 - val_accuracy: 0.8089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e0aa07ddf0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No need to run this, if you are loading the model, if not you cna run this to train your model again and save another weights file.\n",
    "loaded_model_2.fit(X_train, y_train, batch_size=10, epochs=30, validation_split=0.1, callbacks=callbacks_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "yLgYHybPjsJA"
   },
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "loaded_model_3 = load_model(r'C:\\Users\\lenovo\\Downloads\\skin canser\\models\\different_class_accuracy\\weights-best-27-0.99-0.70.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "vMs5hfeBjsJB",
    "outputId": "d48d4d4e-c1ed-495d-a165-1d5b75a92c23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4953608512878418, 0.9289772510528564)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score, acc = loaded_model_3.evaluate(X_test, y_test, verbose=0)\n",
    "score, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "bN5ID895jsJB",
    "outputId": "de7b70f2-5f96-4c80-98f7-5f98633dc8e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 222ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "v8HrJzjCjsJC",
    "outputId": "9d69d0cb-0f0a-4565-d427-03f49a57e825",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.1927471e-02, 9.5828891e-01, 8.9345060e-02],\n",
       "       [9.9920183e-01, 2.3273264e-01, 1.2337971e-01],\n",
       "       [9.7983146e-01, 3.7659678e-01, 3.0868778e-01],\n",
       "       ...,\n",
       "       [2.7623248e-05, 9.3918240e-01, 9.9066138e-01],\n",
       "       [1.0000000e+00, 2.4566036e-03, 2.7020883e-10],\n",
       "       [9.7267836e-01, 9.4421387e-01, 1.0287554e-02]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "GKNCeLZpjsJD",
    "outputId": "fd56e80b-662b-4817-c0bc-350b23427dcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "5G4xySBBjsJE"
   },
   "outputs": [],
   "source": [
    "count = len(y_pred)\n",
    "result = []\n",
    "for i in range(count):\n",
    "    if np.argmax(y_pred[i]) == 0:\n",
    "        result.append(0)\n",
    "    elif np.argmax(y_pred[i]) == 1:\n",
    "        result.append(1)\n",
    "    else:\n",
    "        result.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "ZjKkUhMIjsJF",
    "outputId": "04d0216c-eee7-4de1-9075-1b770379c1c2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "cf_matrix = confusion_matrix(result,y_test)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMfMeQSLjsJG"
   },
   "source": [
    "### Testing on Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "7NF3OZkUjsJH",
    "outputId": "eaa2b1c1-c4fb-44aa-a061-90775a10f6b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test[34] # 2\n",
    "\n",
    "# y_test[54] # 2\n",
    "\n",
    "y_test[89] # 0\n",
    "\n",
    "\n",
    "#y_test[54] # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "PUmtltC2jsJI",
    "outputId": "085dafb9-c48e-4c2d-8405-1c8ae32bdb4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 180, 180, 1)\n"
     ]
    }
   ],
   "source": [
    "xi = np.array(X_test[89]).reshape(-1, 180, 180, 1)\n",
    "print(xi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "Yivg4JnyjsJK",
    "outputId": "297fb098-ff41-4373-d79e-0210d49bdd5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 168ms/step\n",
      "The Person is Having Dermatofibroma\n"
     ]
    }
   ],
   "source": [
    "prediction = loaded_model_3.predict(xi)\n",
    "# np.argmax(prediction)\n",
    "if np.argmax(prediction) == 0:\n",
    "    print(\"THe Person is Having Acnitic Keratosis\")\n",
    "elif np.argmax(prediction) == 1:\n",
    "    print(\"The Person is Having Dermatofibroma\")\n",
    "else:\n",
    "    print(\"The Person is Having Vascular Lesion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "urUznHGjjsJL"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def run(source=None):\n",
    "\n",
    "    model = tensorflow.keras.models.load_model(r'C:\\Users\\lenovo\\Downloads\\skin canser\\models\\different_class_accuracy\\weights-best-27-0.99-0.70.hdf5')\n",
    "\n",
    "    img = cv2.imread(source)\n",
    "\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(img_gray, (5, 5), 0)   \n",
    "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    img_half = cv2.resize(img, (180, 180))\n",
    "    img_half = cv2.cvtColor(img_half, cv2.COLOR_BGR2GRAY)\n",
    "    x = img_to_array(img_half)\n",
    "    x = np.array(x).reshape(-1, 180, 180, 1)\n",
    "    prediction = model.predict(x)\n",
    "    if np.argmax(prediction) == 0:\n",
    "        # print(\"Dont worry your Knee was very safe, take healthy food \")\n",
    "        return 'Acnitic Keratosis'\n",
    "    elif np.argmax(prediction) == 1:\n",
    "        # print(\"The Fabric is Good. \")\n",
    "        return 'Dermatofibroma'\n",
    "    elif np.argmax(prediction) == 2:\n",
    "        # print(\"The Fabric is Good. \")\n",
    "        return 'Vascular Lesion'\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 148ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dermatofibroma'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(source=r\"C:\\Users\\lenovo\\Downloads\\skin canser\\resized_new_classes-20230302T065126Z-001\\resized_new_classes\\D\\images0.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.19.0-py2.py3-none-any.whl (9.6 MB)\n",
      "     ---------------------------------------- 9.6/9.6 MB 12.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (4.3.0)\n",
      "Requirement already satisfied: cachetools>=4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (5.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (4.11.3)\n",
      "Requirement already satisfied: tornado>=6.0.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (6.1)\n",
      "Requirement already satisfied: requests>=2.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (2.28.1)\n",
      "Requirement already satisfied: tzlocal>=1.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (4.2)\n",
      "Collecting pympler>=0.9\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "     ------------------------------------- 164.8/164.8 kB 10.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (1.21.5)\n",
      "Requirement already satisfied: watchdog in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Collecting blinker>=1.0.0\n",
      "  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
      "Collecting pyarrow>=4.0\n",
      "  Downloading pyarrow-11.0.0-cp39-cp39-win_amd64.whl (20.6 MB)\n",
      "     --------------------------------------- 20.6/20.6 MB 10.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (1.4.4)\n",
      "Collecting semver\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (3.19.6)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n",
      "     ---------------------------------------- 4.7/4.7 MB 13.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "     ------------------------------------- 813.6/813.6 kB 12.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (9.2.0)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
      "     ------------------------------------- 239.0/239.0 kB 15.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=14.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (21.3)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Collecting validators>=0.2\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gitpython!=3.1.19\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "     ------------------------------------- 184.3/184.3 kB 10.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: toml in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (4.16.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.11.2)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from click>=7.0->streamlit) (0.4.5)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from importlib-metadata>=1.4->streamlit) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from packaging>=14.1->streamlit) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pandas>=0.25->streamlit) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from python-dateutil->streamlit) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests>=2.4->streamlit) (3.3)\n",
      "Collecting pygments<3.0.0,>=2.14.0\n",
      "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 10.2 MB/s eta 0:00:00\n",
      "Collecting markdown-it-py<3.0.0,>=2.1.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "     ---------------------------------------- 84.5/84.5 kB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tzdata in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tzlocal>=1.1->streamlit) (2022.7)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tzlocal>=1.1->streamlit) (0.1.0.post0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from validators>=0.2->streamlit) (5.1.1)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (21.4.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: validators\n",
      "  Building wheel for validators (setup.py): started\n",
      "  Building wheel for validators (setup.py): finished with status 'done'\n",
      "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=7f1c9d9ff0d17a1a6bd4980d31eaca5834f1d61be7d7289b8ec9bcf2aefe9861\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\2d\\f0\\a8\\1094fca7a7e5d0d12ff56e0c64675d72aa5cc81a5fc200e849\n",
      "Successfully built validators\n",
      "Installing collected packages: validators, smmap, semver, pympler, pygments, pyarrow, mdurl, blinker, pydeck, markdown-it-py, gitdb, rich, gitpython, altair, streamlit\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "Successfully installed altair-4.2.2 blinker-1.5 gitdb-4.0.10 gitpython-3.1.31 markdown-it-py-2.2.0 mdurl-0.1.2 pyarrow-11.0.0 pydeck-0.8.0 pygments-2.14.0 pympler-1.0.1 rich-13.3.1 semver-2.13.0 smmap-5.0.0 streamlit-1.19.0 validators-0.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.2.2 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1 [==============================] - ETA: 0s\n",
      "1/1 [==============================] - 1s 872ms/step\n",
      "C:\\Users\\lenovo\\Downloads\\skin canser\\augmented_new_data\\D\\image_0_9871.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-02 13:31:06.660938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-02 13:31:13.274 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run abc.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "! python abc.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! streamlit run abc.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       117\n",
      "           1       0.87      0.96      0.91       121\n",
      "           2       0.98      0.92      0.95       114\n",
      "\n",
      "    accuracy                           0.93       352\n",
      "   macro avg       0.93      0.93      0.93       352\n",
      "weighted avg       0.93      0.93      0.93       352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, result))\n",
    "# print(f\"Precision Score of the classifier is: {confusion_matrix(y_test, result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "c-K8I31zjsIh",
    "Q2P69nl1jsIu"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "537a1ccab29e2bad0b4d998c04f52d9d2f6eadd1beb35b9ac347a685a31f8869"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
